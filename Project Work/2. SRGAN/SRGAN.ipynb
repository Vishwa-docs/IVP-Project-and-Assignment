{"cells":[{"cell_type":"markdown","metadata":{},"source":["# [SRGANs](https://youtu.be/KsNLxBvJBKo?si=yyuUe1hs9t8d7I8s)\n","\n","- [Taken From](https://www.geeksforgeeks.org/super-resolution-gan-srgan/)"]},{"cell_type":"markdown","metadata":{},"source":["1. <b>Generator</b> The generator takes a low-resolution image (LR) as input and aims to produce a high-resolution super-resolution image (SR). It consists of several layers, including convolutional layers (conv1, conv2, conv3) and residual blocks (rb1, rb2), which help in extracting features and preserving important details from the LR image. The generator also includes upsampling layers (up1, up2) that upscale the LR image to enhance its resolution. Additional layers (add1, add2) further refine the generated image.<br><br>\n","2. <b>Discriminator</b> The discriminator is responsible for distinguishing between real high-resolution images and generated super-resolution images. It takes the SR image as input (input_disc) and produces a discriminator output, indicating the authenticity of the input image. The discriminator comprises convolutional layers (conv1_disc, conv2_disc, conv3_disc) that extract features from the input image. Additional layers (add1_disc, add2_disc) refine the extracted features and contribute to the discriminator's decision-making process.<br><br>\n","3. <b>Perceptual Loss</b> Perceptual loss in SRGAN combines adversarial loss and content loss to guide the training process. Adversarial loss (adv_loss) encourages the generator to produce SR images that the discriminator cannot distinguish from real HR images. Content loss (content_loss) measures the similarity between the generated SR image and the corresponding ground truth high-resolution image. The combination of these losses helps improve the perceptual quality of the generated images.<br><br>\n","4. <b>Connections</b> The SR image generated by the generator is fed as input to both the discriminator and the perceptual loss. The connection from the generator's output to the discriminator (output -> input_disc) enables the discriminator to classify the generated SR image. The connection from the generator's output to the perceptual loss (output -> adv_loss) uses the SR image to calculate the adversarial loss. Simultaneously, the low-resolution input image (LR) is connected to the perceptual loss (input -> content_loss) to calculate the content loss by comparing it to the ground truth high-resolution image.<br><br>\n","The block diagram provides an overview of how the generator, discriminator, and perceptual loss components interact in the SRGAN architecture to achieve high-quality super-resolution image generation.</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:35.255695Z","iopub.status.busy":"2023-07-18T20:37:35.254659Z","iopub.status.idle":"2023-07-18T20:37:35.311161Z","shell.execute_reply":"2023-07-18T20:37:35.310002Z","shell.execute_reply.started":"2023-07-18T20:37:35.255635Z"},"trusted":true},"outputs":[],"source":["# from IPython.display import SVG, display\n","# svg_file = '/kaggle/input/machine-learning-architecture-diagrams/SRGAN.svg'\n","# display(SVG(filename=svg_file))"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:41.460072Z","iopub.status.busy":"2023-07-18T20:37:41.459139Z","iopub.status.idle":"2023-07-18T20:37:44.204621Z","shell.execute_reply":"2023-07-18T20:37:44.203550Z","shell.execute_reply.started":"2023-07-18T20:37:41.460018Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader,Dataset\n","import torch.optim as optim\n","from torchvision.models.vgg import vgg16\n","from math import exp\n","import torch\n","import torch.nn.functional as F\n","import torchvision.utils as utils\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import math\n","import pandas as pd\n","import os\n","from os import listdir\n","import numpy as np\n","from PIL import Image\n","from os.path import join"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.207542Z","iopub.status.busy":"2023-07-18T20:37:44.206880Z","iopub.status.idle":"2023-07-18T20:37:44.273083Z","shell.execute_reply":"2023-07-18T20:37:44.271882Z","shell.execute_reply.started":"2023-07-18T20:37:44.207500Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.276026Z","iopub.status.busy":"2023-07-18T20:37:44.275006Z","iopub.status.idle":"2023-07-18T20:37:44.290288Z","shell.execute_reply":"2023-07-18T20:37:44.288976Z","shell.execute_reply.started":"2023-07-18T20:37:44.275983Z"},"trusted":true},"outputs":[],"source":["upscale_factor = 8\n","crop_size= 88\n","num_epochs= 10"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.295056Z","iopub.status.busy":"2023-07-18T20:37:44.293853Z","iopub.status.idle":"2023-07-18T20:37:44.302007Z","shell.execute_reply":"2023-07-18T20:37:44.301173Z","shell.execute_reply.started":"2023-07-18T20:37:44.295016Z"},"trusted":true},"outputs":[],"source":["mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.304768Z","iopub.status.busy":"2023-07-18T20:37:44.303801Z","iopub.status.idle":"2023-07-18T20:37:44.314697Z","shell.execute_reply":"2023-07-18T20:37:44.313830Z","shell.execute_reply.started":"2023-07-18T20:37:44.304729Z"},"trusted":true},"outputs":[],"source":["def is_image(filename):\n","  return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n","\n","def calc_valid_crop_size(crop_size,upscale_factor):\n","  return crop_size - (crop_size % upscale_factor)\n","\n","def train_high_res_transform(crop_size):\n","  return transforms.Compose([transforms.RandomCrop(crop_size), transforms.ToTensor()])\n","\n","def train_low_res_transform(crop_size,upscale_factor):\n","  return transforms.Compose([transforms.ToPILImage(), transforms.Resize(crop_size//upscale_factor, interpolation = Image.BICUBIC), transforms.ToTensor()])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.317390Z","iopub.status.busy":"2023-07-18T20:37:44.316377Z","iopub.status.idle":"2023-07-18T20:37:44.327267Z","shell.execute_reply":"2023-07-18T20:37:44.326454Z","shell.execute_reply.started":"2023-07-18T20:37:44.317350Z"},"trusted":true},"outputs":[],"source":["class TrainDataFromFolder(Dataset):\n","  def __init__(self,data_dir, crop_size, upscale_factor):\n","    super().__init__()\n","    self.image_file_names = [join(data_dir,x) for x in listdir(data_dir) if is_image(x)]\n","    crop_size = calc_valid_crop_size(crop_size, upscale_factor)\n","    self.high_res_transform = train_high_res_transform(crop_size)\n","    self.low_res_transform = train_low_res_transform(crop_size,upscale_factor)\n","\n","  def __getitem__(self,index):\n","    hr_image = self.high_res_transform(Image.open(self.image_file_names[index]))\n","    lr_image = self.low_res_transform(hr_image)\n","    return lr_image, hr_image\n","\n","  def __len__(self):\n","    return len(self.image_file_names)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.330107Z","iopub.status.busy":"2023-07-18T20:37:44.328467Z","iopub.status.idle":"2023-07-18T20:37:44.343143Z","shell.execute_reply":"2023-07-18T20:37:44.341994Z","shell.execute_reply.started":"2023-07-18T20:37:44.330073Z"},"trusted":true},"outputs":[],"source":["class ValDataFromFolder(Dataset):\n","  def __init__(self,data_dir, upscale_factor):\n","    super().__init__()\n","    self.upscale_factor = upscale_factor\n","    self.image_file_names = [join(data_dir,x) for x in listdir(data_dir) if is_image(x)]\n","\n","  def __getitem__(self,index):\n","    hr_image = Image.open(self.image_file_names[index])\n","    w,h = hr_image.size\n","    crop_size = calc_valid_crop_size(min(w,h), self.upscale_factor)\n","    lr_scale = transforms.Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n","    hr_scale = transforms.Resize(crop_size, interpolation=Image.BICUBIC)\n","    hr_image = transforms.CenterCrop(crop_size)(hr_image)\n","    lr_image = lr_scale(hr_image)\n","    hr_restored_image = hr_scale(lr_image)\n","    return transforms.ToTensor()(lr_image), transforms.ToTensor()(hr_restored_image), transforms.ToTensor()(hr_image)\n","\n","  def __len__(self):\n","    return len(self.image_file_names)\n","    "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:37:44.346794Z","iopub.status.busy":"2023-07-18T20:37:44.345844Z","iopub.status.idle":"2023-07-18T20:37:44.696423Z","shell.execute_reply":"2023-07-18T20:37:44.695238Z","shell.execute_reply.started":"2023-07-18T20:37:44.346755Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:330: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n","  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n","/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["train_set = TrainDataFromFolder('/kaggle/input/div2k-dataset/DIV2K_train_HR/DIV2K_train_HR', crop_size=crop_size, upscale_factor=upscale_factor)\n","val_set = ValDataFromFolder('/kaggle/input/div2k-dataset/DIV2K_valid_HR/DIV2K_valid_HR', upscale_factor=upscale_factor)\n","train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n","val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2023-07-18T20:37:44.698955Z","iopub.status.busy":"2023-07-18T20:37:44.698222Z","iopub.status.idle":"2023-07-18T20:38:27.833025Z","shell.execute_reply":"2023-07-18T20:38:27.831345Z","shell.execute_reply.started":"2023-07-18T20:37:44.698898Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([[[[0.1961, 0.1529, 0.0745,  ..., 0.2353, 0.2118, 0.2549],\n","          [0.1647, 0.1490, 0.1412,  ..., 0.1961, 0.2784, 0.2627],\n","          [0.2118, 0.1647, 0.1569,  ..., 0.2902, 0.2667, 0.2549],\n","          ...,\n","          [0.2196, 0.1529, 0.2784,  ..., 0.2784, 0.2824, 0.2863],\n","          [0.2157, 0.2549, 0.3059,  ..., 0.2863, 0.2863, 0.2941],\n","          [0.3059, 0.3294, 0.3020,  ..., 0.2980, 0.2980, 0.3059]],\n","\n","         [[0.1608, 0.1176, 0.0588,  ..., 0.2039, 0.1922, 0.4588],\n","          [0.1294, 0.1137, 0.1059,  ..., 0.1804, 0.4706, 0.5961],\n","          [0.1686, 0.1294, 0.1255,  ..., 0.5020, 0.5961, 0.5804],\n","          ...,\n","          [0.1882, 0.1294, 0.4784,  ..., 0.5882, 0.5922, 0.5961],\n","          [0.2235, 0.3961, 0.5922,  ..., 0.5961, 0.5961, 0.6000],\n","          [0.4392, 0.6275, 0.5961,  ..., 0.6000, 0.6039, 0.6078]],\n","\n","         [[0.1569, 0.1216, 0.0706,  ..., 0.2118, 0.2824, 0.7098],\n","          [0.1333, 0.1176, 0.1176,  ..., 0.2588, 0.7176, 0.8275],\n","          [0.1686, 0.1294, 0.1373,  ..., 0.7569, 0.8196, 0.8039],\n","          ...,\n","          [0.1922, 0.1922, 0.7059,  ..., 0.8078, 0.8118, 0.8157],\n","          [0.3294, 0.6235, 0.8196,  ..., 0.8157, 0.8157, 0.8196],\n","          [0.6588, 0.8471, 0.8118,  ..., 0.8196, 0.8235, 0.8275]]],\n","\n","\n","        [[[0.9922, 0.9961, 1.0000,  ..., 0.9333, 0.9137, 0.8980],\n","          [0.9961, 0.9922, 0.9804,  ..., 0.9059, 0.8980, 0.8941],\n","          [0.9686, 0.9608, 0.9490,  ..., 0.8980, 0.8863, 0.8784],\n","          ...,\n","          [0.9098, 0.9098, 0.9098,  ..., 0.8902, 0.8863, 0.8784],\n","          [0.8902, 0.8941, 0.8980,  ..., 0.9020, 0.8980, 0.8941],\n","          [0.8941, 0.8902, 0.8941,  ..., 0.9059, 0.9059, 0.9059]],\n","\n","         [[0.8745, 0.8784, 0.8824,  ..., 0.8314, 0.8118, 0.8000],\n","          [0.8745, 0.8706, 0.8588,  ..., 0.8078, 0.8039, 0.8000],\n","          [0.8510, 0.8471, 0.8353,  ..., 0.8039, 0.7961, 0.7922],\n","          ...,\n","          [0.8078, 0.8078, 0.8078,  ..., 0.8000, 0.8000, 0.8000],\n","          [0.8000, 0.8000, 0.8039,  ..., 0.8078, 0.8078, 0.8078],\n","          [0.8000, 0.8000, 0.8000,  ..., 0.8118, 0.8118, 0.8118]],\n","\n","         [[0.8078, 0.8078, 0.8118,  ..., 0.8000, 0.7961, 0.7882],\n","          [0.8118, 0.8078, 0.8078,  ..., 0.7922, 0.7922, 0.7882],\n","          [0.8039, 0.8039, 0.8000,  ..., 0.7882, 0.7882, 0.7843],\n","          ...,\n","          [0.7843, 0.7843, 0.7843,  ..., 0.7843, 0.7843, 0.7843],\n","          [0.7765, 0.7765, 0.7804,  ..., 0.7843, 0.7843, 0.7882],\n","          [0.7765, 0.7765, 0.7804,  ..., 0.7843, 0.7882, 0.7882]]],\n","\n","\n","        [[[0.0627, 0.0745, 0.0980,  ..., 0.0392, 0.0824, 0.1020],\n","          [0.1255, 0.1922, 0.2392,  ..., 0.0588, 0.0627, 0.0431],\n","          [0.6745, 0.5765, 0.1922,  ..., 0.0157, 0.0784, 0.1529],\n","          ...,\n","          [0.1490, 0.1020, 0.1922,  ..., 0.0157, 0.0902, 0.1255],\n","          [0.2196, 0.3059, 0.2157,  ..., 0.1843, 0.1686, 0.0980],\n","          [0.3725, 0.4275, 0.4353,  ..., 0.2706, 0.2588, 0.2667]],\n","\n","         [[0.1608, 0.1569, 0.1529,  ..., 0.0941, 0.1412, 0.1451],\n","          [0.1882, 0.2392, 0.3137,  ..., 0.0941, 0.1137, 0.1020],\n","          [0.6667, 0.5020, 0.2510,  ..., 0.0471, 0.1059, 0.1647],\n","          ...,\n","          [0.2510, 0.1961, 0.2549,  ..., 0.0667, 0.1490, 0.1765],\n","          [0.2471, 0.3294, 0.2627,  ..., 0.2431, 0.2118, 0.1686],\n","          [0.3412, 0.4196, 0.4745,  ..., 0.3255, 0.3333, 0.3137]],\n","\n","         [[0.0314, 0.0353, 0.0431,  ..., 0.0235, 0.0431, 0.0549],\n","          [0.0588, 0.0745, 0.0941,  ..., 0.0275, 0.0314, 0.0235],\n","          [0.5647, 0.4588, 0.0784,  ..., 0.0078, 0.0275, 0.0471],\n","          ...,\n","          [0.0706, 0.0431, 0.0745,  ..., 0.0118, 0.0353, 0.0471],\n","          [0.0980, 0.1569, 0.1098,  ..., 0.0824, 0.0745, 0.0471],\n","          [0.1569, 0.1804, 0.1843,  ..., 0.1098, 0.1137, 0.1333]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.1373, 0.1294, 0.1137,  ..., 0.1725, 0.1843, 0.1922],\n","          [0.1412, 0.1333, 0.1176,  ..., 0.1922, 0.2000, 0.2000],\n","          [0.1490, 0.1569, 0.1490,  ..., 0.2118, 0.2157, 0.2118],\n","          ...,\n","          [0.1647, 0.1608, 0.1725,  ..., 0.2039, 0.1843, 0.1686],\n","          [0.1333, 0.1412, 0.1608,  ..., 0.1804, 0.1686, 0.1529],\n","          [0.1098, 0.1216, 0.1333,  ..., 0.1608, 0.1569, 0.1412]],\n","\n","         [[0.1176, 0.1176, 0.1059,  ..., 0.1647, 0.1686, 0.1765],\n","          [0.1255, 0.1216, 0.1137,  ..., 0.1765, 0.1804, 0.1843],\n","          [0.1373, 0.1412, 0.1412,  ..., 0.1922, 0.1922, 0.1922],\n","          ...,\n","          [0.1451, 0.1529, 0.1647,  ..., 0.1843, 0.1686, 0.1529],\n","          [0.1255, 0.1333, 0.1569,  ..., 0.1686, 0.1608, 0.1451],\n","          [0.0980, 0.1059, 0.1255,  ..., 0.1529, 0.1529, 0.1373]],\n","\n","         [[0.1020, 0.0902, 0.0863,  ..., 0.1216, 0.1255, 0.1294],\n","          [0.0941, 0.0941, 0.0902,  ..., 0.1333, 0.1333, 0.1373],\n","          [0.1059, 0.1098, 0.1137,  ..., 0.1451, 0.1490, 0.1412],\n","          ...,\n","          [0.1216, 0.1216, 0.1294,  ..., 0.1373, 0.1255, 0.1137],\n","          [0.1059, 0.1098, 0.1216,  ..., 0.1216, 0.1137, 0.1059],\n","          [0.0824, 0.0902, 0.0980,  ..., 0.1059, 0.1059, 0.0980]]],\n","\n","\n","        [[[0.7255, 0.5725, 0.3137,  ..., 0.3137, 0.2353, 0.2431],\n","          [0.6431, 0.6392, 0.5922,  ..., 0.3137, 0.2157, 0.2157],\n","          [0.5569, 0.5961, 0.5686,  ..., 0.3333, 0.2118, 0.2000],\n","          ...,\n","          [0.6784, 0.5569, 0.5882,  ..., 0.2784, 0.1725, 0.1294],\n","          [0.7490, 0.6980, 0.6980,  ..., 0.1804, 0.1255, 0.0667],\n","          [0.4471, 0.3216, 0.2627,  ..., 0.1333, 0.1137, 0.0941]],\n","\n","         [[0.5686, 0.4980, 0.3020,  ..., 0.3333, 0.2549, 0.2627],\n","          [0.5725, 0.5765, 0.5294,  ..., 0.3373, 0.2392, 0.2392],\n","          [0.5059, 0.5373, 0.5137,  ..., 0.3490, 0.2353, 0.2235],\n","          ...,\n","          [0.6039, 0.4980, 0.5255,  ..., 0.2824, 0.2157, 0.1725],\n","          [0.6471, 0.6157, 0.6157,  ..., 0.2078, 0.1686, 0.1216],\n","          [0.3765, 0.3059, 0.2667,  ..., 0.1765, 0.1608, 0.1412]],\n","\n","         [[0.4980, 0.4588, 0.2941,  ..., 0.3098, 0.2510, 0.2588],\n","          [0.5137, 0.5176, 0.4784,  ..., 0.3137, 0.2392, 0.2392],\n","          [0.4471, 0.4745, 0.4627,  ..., 0.3255, 0.2353, 0.2235],\n","          ...,\n","          [0.5333, 0.4431, 0.4627,  ..., 0.2706, 0.2235, 0.1804],\n","          [0.5686, 0.5412, 0.5412,  ..., 0.2078, 0.1725, 0.1333],\n","          [0.3294, 0.2824, 0.2510,  ..., 0.1843, 0.1686, 0.1529]]],\n","\n","\n","        [[[0.5765, 0.6157, 0.6667,  ..., 0.2824, 0.3608, 0.3412],\n","          [0.4510, 0.4667, 0.5059,  ..., 0.3176, 0.2471, 0.2353],\n","          [0.5020, 0.4980, 0.4941,  ..., 0.4824, 0.3882, 0.3647],\n","          ...,\n","          [0.4902, 0.4196, 0.3765,  ..., 0.1137, 0.2314, 0.2039],\n","          [0.4980, 0.5529, 0.5529,  ..., 0.1686, 0.1961, 0.3725],\n","          [0.4824, 0.4667, 0.6078,  ..., 0.0431, 0.1922, 0.3608]],\n","\n","         [[0.6078, 0.6510, 0.6980,  ..., 0.2824, 0.3529, 0.3529],\n","          [0.4588, 0.4784, 0.5294,  ..., 0.3255, 0.2510, 0.2471],\n","          [0.5059, 0.5020, 0.5020,  ..., 0.5098, 0.4039, 0.3843],\n","          ...,\n","          [0.4745, 0.3843, 0.3529,  ..., 0.0667, 0.1529, 0.1412],\n","          [0.4745, 0.5176, 0.5490,  ..., 0.1098, 0.1216, 0.2510],\n","          [0.4863, 0.4784, 0.6157,  ..., 0.0275, 0.1255, 0.2549]],\n","\n","         [[0.6353, 0.6902, 0.7294,  ..., 0.3059, 0.3490, 0.3843],\n","          [0.4745, 0.4941, 0.5608,  ..., 0.3569, 0.2745, 0.2863],\n","          [0.5373, 0.5216, 0.5294,  ..., 0.5569, 0.4431, 0.4235],\n","          ...,\n","          [0.4706, 0.3765, 0.3569,  ..., 0.0627, 0.1412, 0.1255],\n","          [0.4706, 0.5059, 0.5529,  ..., 0.1059, 0.1137, 0.2235],\n","          [0.4941, 0.4902, 0.6157,  ..., 0.0275, 0.1294, 0.2392]]]]), tensor([[[[0.1843, 0.1569, 0.1490,  ..., 0.4235, 0.3098, 0.2902],\n","          [0.1922, 0.1686, 0.1216,  ..., 0.3255, 0.2863, 0.2784],\n","          [0.1843, 0.1765, 0.1882,  ..., 0.2863, 0.2706, 0.2588],\n","          ...,\n","          [0.1882, 0.1804, 0.2275,  ..., 0.3059, 0.3098, 0.3059],\n","          [0.1765, 0.1882, 0.2157,  ..., 0.3098, 0.3098, 0.3059],\n","          [0.1725, 0.2118, 0.2196,  ..., 0.3098, 0.3098, 0.3137]],\n","\n","         [[0.1529, 0.1333, 0.1216,  ..., 0.6471, 0.6000, 0.6039],\n","          [0.1569, 0.1294, 0.1020,  ..., 0.6078, 0.5961, 0.6000],\n","          [0.1529, 0.1373, 0.1569,  ..., 0.5922, 0.5882, 0.5922],\n","          ...,\n","          [0.1608, 0.1451, 0.1922,  ..., 0.6078, 0.6118, 0.6078],\n","          [0.1490, 0.1529, 0.1961,  ..., 0.6118, 0.6118, 0.6078],\n","          [0.1451, 0.1686, 0.2118,  ..., 0.6118, 0.6118, 0.6157]],\n","\n","         [[0.1490, 0.1255, 0.1098,  ..., 0.9216, 0.8275, 0.8392],\n","          [0.1608, 0.1333, 0.0863,  ..., 0.8510, 0.8275, 0.8275],\n","          [0.1490, 0.1412, 0.1451,  ..., 0.8235, 0.8196, 0.8157],\n","          ...,\n","          [0.2000, 0.2235, 0.4549,  ..., 0.8275, 0.8314, 0.8275],\n","          [0.1882, 0.2588, 0.4824,  ..., 0.8314, 0.8314, 0.8275],\n","          [0.1922, 0.3137, 0.5255,  ..., 0.8314, 0.8314, 0.8353]]],\n","\n","\n","        [[[0.9529, 0.9608, 0.9686,  ..., 0.9020, 0.9020, 0.9020],\n","          [0.9647, 0.9725, 0.9765,  ..., 0.8941, 0.8941, 0.8902],\n","          [0.9765, 0.9804, 0.9843,  ..., 0.8902, 0.8902, 0.8824],\n","          ...,\n","          [0.8941, 0.8980, 0.8980,  ..., 0.9059, 0.9059, 0.9059],\n","          [0.9059, 0.9098, 0.8980,  ..., 0.9059, 0.9098, 0.9059],\n","          [0.9059, 0.9098, 0.9137,  ..., 0.9059, 0.9020, 0.9020]],\n","\n","         [[0.8431, 0.8471, 0.8510,  ..., 0.8000, 0.7961, 0.8000],\n","          [0.8510, 0.8549, 0.8627,  ..., 0.8000, 0.7961, 0.7961],\n","          [0.8627, 0.8667, 0.8667,  ..., 0.7961, 0.7961, 0.8000],\n","          ...,\n","          [0.8078, 0.8039, 0.8000,  ..., 0.8157, 0.8157, 0.8157],\n","          [0.8078, 0.8078, 0.8078,  ..., 0.8157, 0.8196, 0.8196],\n","          [0.8118, 0.8118, 0.8118,  ..., 0.8118, 0.8078, 0.8078]],\n","\n","         [[0.8039, 0.8039, 0.8118,  ..., 0.7922, 0.7922, 0.7922],\n","          [0.8078, 0.8078, 0.8118,  ..., 0.7843, 0.7804, 0.7804],\n","          [0.8078, 0.8078, 0.8118,  ..., 0.7882, 0.7882, 0.7882],\n","          ...,\n","          [0.7804, 0.7843, 0.7804,  ..., 0.7922, 0.7882, 0.7882],\n","          [0.7843, 0.7843, 0.7804,  ..., 0.7922, 0.7882, 0.7882],\n","          [0.7882, 0.7804, 0.7843,  ..., 0.7882, 0.7961, 0.7922]]],\n","\n","\n","        [[[0.0941, 0.0588, 0.0784,  ..., 0.0235, 0.0275, 0.0235],\n","          [0.0353, 0.0314, 0.0118,  ..., 0.0471, 0.0353, 0.0039],\n","          [0.0431, 0.0235, 0.0314,  ..., 0.1059, 0.2980, 0.1451],\n","          ...,\n","          [0.4196, 0.4078, 0.4980,  ..., 0.3255, 0.4392, 0.2667],\n","          [0.3529, 0.4824, 0.4980,  ..., 0.5333, 0.2471, 0.0235],\n","          [0.3647, 0.4353, 0.4431,  ..., 0.1725, 0.0431, 0.0196]],\n","\n","         [[0.1922, 0.1608, 0.1922,  ..., 0.0784, 0.1216, 0.1059],\n","          [0.1294, 0.1333, 0.1216,  ..., 0.1255, 0.0980, 0.0902],\n","          [0.1333, 0.1176, 0.1333,  ..., 0.1725, 0.2941, 0.1608],\n","          ...,\n","          [0.3765, 0.3608, 0.4314,  ..., 0.3412, 0.4353, 0.2706],\n","          [0.3255, 0.4157, 0.4196,  ..., 0.5137, 0.2588, 0.0745],\n","          [0.3255, 0.3725, 0.3922,  ..., 0.1882, 0.0784, 0.0980]],\n","\n","         [[0.0510, 0.0353, 0.0392,  ..., 0.0118, 0.0157, 0.0078],\n","          [0.0196, 0.0353, 0.0196,  ..., 0.0235, 0.0039, 0.0118],\n","          [0.0196, 0.0157, 0.0314,  ..., 0.0510, 0.1608, 0.0471],\n","          ...,\n","          [0.1373, 0.1255, 0.2235,  ..., 0.1059, 0.2000, 0.1490],\n","          [0.0902, 0.1882, 0.2196,  ..., 0.2941, 0.1294, 0.0039],\n","          [0.1059, 0.1647, 0.1843,  ..., 0.0706, 0.0118, 0.0196]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.1373, 0.1333, 0.1412,  ..., 0.1961, 0.1804, 0.1922],\n","          [0.1412, 0.1451, 0.1333,  ..., 0.1882, 0.1922, 0.2078],\n","          [0.1333, 0.1373, 0.1451,  ..., 0.2000, 0.1882, 0.2039],\n","          ...,\n","          [0.1020, 0.0980, 0.1216,  ..., 0.1373, 0.1412, 0.1373],\n","          [0.1059, 0.0980, 0.1216,  ..., 0.1490, 0.1451, 0.1294],\n","          [0.0941, 0.1020, 0.0941,  ..., 0.1451, 0.1412, 0.1294]],\n","\n","         [[0.1333, 0.1255, 0.1255,  ..., 0.1725, 0.1608, 0.1725],\n","          [0.1294, 0.1294, 0.1137,  ..., 0.1765, 0.1686, 0.1804],\n","          [0.1137, 0.1176, 0.1176,  ..., 0.1882, 0.1765, 0.1765],\n","          ...,\n","          [0.0824, 0.0941, 0.1098,  ..., 0.1216, 0.1255, 0.1216],\n","          [0.0941, 0.0980, 0.1098,  ..., 0.1373, 0.1333, 0.1176],\n","          [0.0863, 0.1020, 0.0941,  ..., 0.1373, 0.1373, 0.1294]],\n","\n","         [[0.1059, 0.1059, 0.1059,  ..., 0.1137, 0.1098, 0.1255],\n","          [0.1137, 0.1137, 0.0941,  ..., 0.1216, 0.1176, 0.1333],\n","          [0.1020, 0.1059, 0.1059,  ..., 0.1412, 0.1255, 0.1294],\n","          ...,\n","          [0.0706, 0.0745, 0.0863,  ..., 0.0902, 0.0902, 0.0902],\n","          [0.0745, 0.0745, 0.0902,  ..., 0.1020, 0.0980, 0.0863],\n","          [0.0706, 0.0784, 0.0745,  ..., 0.0902, 0.0941, 0.0941]]],\n","\n","\n","        [[[0.9569, 0.9686, 0.9412,  ..., 0.5922, 0.5490, 0.4745],\n","          [0.7098, 0.7255, 0.7608,  ..., 0.0824, 0.0863, 0.0824],\n","          [0.7333, 0.7647, 0.6824,  ..., 0.1294, 0.1020, 0.1020],\n","          ...,\n","          [0.1843, 0.4000, 0.5961,  ..., 0.1137, 0.0824, 0.0706],\n","          [0.1765, 0.2392, 0.2471,  ..., 0.1216, 0.1529, 0.0784],\n","          [0.1961, 0.3059, 0.3255,  ..., 0.2392, 0.1608, 0.0745]],\n","\n","         [[0.8784, 0.8902, 0.8431,  ..., 0.5608, 0.5176, 0.4471],\n","          [0.5961, 0.6039, 0.6196,  ..., 0.1255, 0.1333, 0.1373],\n","          [0.5804, 0.5765, 0.4863,  ..., 0.1725, 0.1412, 0.1451],\n","          ...,\n","          [0.1804, 0.3412, 0.4824,  ..., 0.1647, 0.1333, 0.1294],\n","          [0.1961, 0.2392, 0.2039,  ..., 0.1765, 0.2078, 0.1333],\n","          [0.2118, 0.3216, 0.3059,  ..., 0.3059, 0.2157, 0.1255]],\n","\n","         [[0.8235, 0.8275, 0.7804,  ..., 0.5176, 0.4863, 0.4196],\n","          [0.5255, 0.5333, 0.5412,  ..., 0.1333, 0.1490, 0.1490],\n","          [0.4784, 0.4784, 0.3961,  ..., 0.1882, 0.1608, 0.1608],\n","          ...,\n","          [0.1647, 0.3098, 0.4353,  ..., 0.1647, 0.1333, 0.1294],\n","          [0.1882, 0.2275, 0.1843,  ..., 0.1765, 0.2078, 0.1373],\n","          [0.2039, 0.3020, 0.2824,  ..., 0.3020, 0.2157, 0.1294]]],\n","\n","\n","        [[[0.5765, 0.5529, 0.5647,  ..., 0.4941, 0.4353, 0.4235],\n","          [0.5490, 0.5451, 0.5608,  ..., 0.3216, 0.2784, 0.3020],\n","          [0.6039, 0.5765, 0.5686,  ..., 0.2392, 0.3137, 0.3843],\n","          ...,\n","          [0.6627, 0.4745, 0.4941,  ..., 0.3961, 0.1255, 0.0588],\n","          [0.6627, 0.5569, 0.4392,  ..., 0.2078, 0.0588, 0.0549],\n","          [0.5882, 0.6157, 0.5216,  ..., 0.0706, 0.0667, 0.0510]],\n","\n","         [[0.6196, 0.5922, 0.6000,  ..., 0.5098, 0.4706, 0.4667],\n","          [0.5882, 0.5843, 0.5961,  ..., 0.3412, 0.2980, 0.3216],\n","          [0.6275, 0.6078, 0.6078,  ..., 0.2353, 0.3255, 0.4157],\n","          ...,\n","          [0.6667, 0.4745, 0.4980,  ..., 0.2824, 0.0863, 0.0706],\n","          [0.6667, 0.5569, 0.4431,  ..., 0.1412, 0.0431, 0.0549],\n","          [0.5922, 0.6196, 0.5255,  ..., 0.0471, 0.0706, 0.0549]],\n","\n","         [[0.6549, 0.6275, 0.6353,  ..., 0.5373, 0.5098, 0.5137],\n","          [0.6314, 0.6196, 0.6275,  ..., 0.3412, 0.3294, 0.3725],\n","          [0.6706, 0.6431, 0.6353,  ..., 0.3176, 0.4588, 0.5569],\n","          ...,\n","          [0.6706, 0.4824, 0.5059,  ..., 0.2275, 0.0549, 0.0588],\n","          [0.6745, 0.5647, 0.4510,  ..., 0.0980, 0.0235, 0.0667],\n","          [0.6078, 0.6314, 0.5333,  ..., 0.0314, 0.0784, 0.0745]]]])]\n"]}],"source":["for batch in train_loader:\n","  print(batch)\n","  break"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.840243Z","iopub.status.busy":"2023-07-18T20:38:27.839496Z","iopub.status.idle":"2023-07-18T20:38:27.850054Z","shell.execute_reply":"2023-07-18T20:38:27.848727Z","shell.execute_reply.started":"2023-07-18T20:38:27.840191Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","  def __init__(self, channels):\n","    super(ResidualBlock, self).__init__()\n","    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn1 = nn.BatchNorm2d(channels)\n","    self.prelu = nn.PReLU()\n","    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn2 = nn.BatchNorm2d(channels)\n","  def forward(self, x):\n","    residual = self.conv1(x)\n","    residual = self.bn1(residual)\n","    residual = self.prelu(residual)\n","    residual = self.conv2(residual)\n","    residual = self.bn2(residual)\n","    return x + residual"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.852821Z","iopub.status.busy":"2023-07-18T20:38:27.851887Z","iopub.status.idle":"2023-07-18T20:38:27.864422Z","shell.execute_reply":"2023-07-18T20:38:27.863292Z","shell.execute_reply.started":"2023-07-18T20:38:27.852780Z"},"trusted":true},"outputs":[],"source":["class UpsampleBlock(nn.Module):\n","  def __init__(self, in_channels, up_scale):\n","    super(UpsampleBlock, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, \n","                          kernel_size=3, padding=1)\n","    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n","    self.prelu = nn.PReLU()\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.pixel_shuffle(x)\n","    x = self.prelu(x)\n","    return x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.867158Z","iopub.status.busy":"2023-07-18T20:38:27.866209Z","iopub.status.idle":"2023-07-18T20:38:27.883617Z","shell.execute_reply":"2023-07-18T20:38:27.882571Z","shell.execute_reply.started":"2023-07-18T20:38:27.867069Z"},"trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","  def __init__(self, scale_factor):\n","    super(Generator, self).__init__()\n","    upsample_block_num = int(math.log(scale_factor, 2))\n","\n","    self.block1 = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n","        nn.PReLU()\n","    )\n","\n","    self.block2 = ResidualBlock(64)\n","    self.block3 = ResidualBlock(64)\n","    self.block4 = ResidualBlock(64)\n","    self.block5 = ResidualBlock(64)\n","    self.block6 = ResidualBlock(64)\n","    self.block7 = nn.Sequential(\n","        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(64)\n","    )\n","    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n","    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n","    self.block8 = nn.Sequential(*block8)\n","  def forward(self, x):\n","    block1 = self.block1(x)\n","    block2 = self.block2(block1)\n","    block3 = self.block3(block2)\n","    block4 = self.block4(block3)\n","    block5 = self.block5(block4)\n","    block6 = self.block6(block5)\n","    block7 = self.block7(block6)\n","    block8 = self.block8(block1 + block7)\n","    return (torch.tanh(block8) + 1) / 2\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.886047Z","iopub.status.busy":"2023-07-18T20:38:27.885044Z","iopub.status.idle":"2023-07-18T20:38:27.905869Z","shell.execute_reply":"2023-07-18T20:38:27.904800Z","shell.execute_reply.started":"2023-07-18T20:38:27.886002Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.net = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.AdaptiveAvgPool2d(1),\n","        nn.Conv2d(512, 1024, kernel_size=1),\n","        nn.LeakyReLU(0.2),\n","        nn.Conv2d(1024, 1, kernel_size=1)\n","    )\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    return torch.sigmoid(self.net(x).view(batch_size))\n","     "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.907977Z","iopub.status.busy":"2023-07-18T20:38:27.907412Z","iopub.status.idle":"2023-07-18T20:38:27.920887Z","shell.execute_reply":"2023-07-18T20:38:27.919691Z","shell.execute_reply.started":"2023-07-18T20:38:27.907917Z"},"trusted":true},"outputs":[],"source":["class TVLoss(nn.Module):\n","  def __init__(self, tv_loss_weight=1):\n","    super(TVLoss, self).__init__()\n","    self.tv_loss_weight=tv_loss_weight\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    h_x = x.size()[2]\n","    w_x = x.size()[3]\n","\n","    count_h = self.tensor_size(x[:, :, 1:, :])\n","    count_w = self.tensor_size(x[:, :, :, 1:])\n","\n","    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n","    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n","    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n","  \n","  @staticmethod \n","  def tensor_size(t):\n","    return t.size()[1] * t.size()[2] * t.size()[3]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.922969Z","iopub.status.busy":"2023-07-18T20:38:27.922490Z","iopub.status.idle":"2023-07-18T20:38:27.933483Z","shell.execute_reply":"2023-07-18T20:38:27.932163Z","shell.execute_reply.started":"2023-07-18T20:38:27.922911Z"},"trusted":true},"outputs":[],"source":["\n","class GeneratorLoss(nn.Module):\n","  def __init__(self):\n","    super(GeneratorLoss, self).__init__()\n","    vgg = vgg16(pretrained=True)\n","    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n","    for param in loss_network.parameters():\n","      param.requires_grad = False\n","    self.loss_network = loss_network\n","    self.mse_loss = nn.MSELoss()\n","    self.tv_loss = TVLoss()\n","  def forward(self, out_labels, out_images, target_images):\n","    adversial_loss = torch.mean(1 - out_labels)\n","    perception_loss = self.mse_loss(out_images, target_images)\n","    image_loss = self.mse_loss(out_images, target_images)\n","    tv_loss = self.tv_loss(out_images)\n","    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:27.935374Z","iopub.status.busy":"2023-07-18T20:38:27.934949Z","iopub.status.idle":"2023-07-18T20:38:28.020191Z","shell.execute_reply":"2023-07-18T20:38:28.019169Z","shell.execute_reply.started":"2023-07-18T20:38:27.935337Z"},"trusted":true},"outputs":[],"source":["netG = Generator(upscale_factor)\n","netD = Discriminator()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:28.022163Z","iopub.status.busy":"2023-07-18T20:38:28.021795Z","iopub.status.idle":"2023-07-18T20:38:33.169683Z","shell.execute_reply":"2023-07-18T20:38:33.168523Z","shell.execute_reply.started":"2023-07-18T20:38:28.022126Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n","/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7c800fef4424f11885e304b50078bcb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/528M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["generator_criterion = GeneratorLoss()\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:33.171723Z","iopub.status.busy":"2023-07-18T20:38:33.171246Z","iopub.status.idle":"2023-07-18T20:38:35.896576Z","shell.execute_reply":"2023-07-18T20:38:35.895423Z","shell.execute_reply.started":"2023-07-18T20:38:33.171683Z"},"trusted":true},"outputs":[],"source":["generator_criterion = generator_criterion.to(device)\n","netG = netG.to(device)\n","netD = netD.to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.898866Z","iopub.status.busy":"2023-07-18T20:38:35.898105Z","iopub.status.idle":"2023-07-18T20:38:35.906913Z","shell.execute_reply":"2023-07-18T20:38:35.905841Z","shell.execute_reply.started":"2023-07-18T20:38:35.898820Z"},"trusted":true},"outputs":[],"source":["optimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n","optimizerD = optim.Adam(netD.parameters(), lr=0.0002)\n","     "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.909898Z","iopub.status.busy":"2023-07-18T20:38:35.908774Z","iopub.status.idle":"2023-07-18T20:38:35.929474Z","shell.execute_reply":"2023-07-18T20:38:35.928311Z","shell.execute_reply.started":"2023-07-18T20:38:35.909855Z"},"trusted":true},"outputs":[],"source":["def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n","    return gauss / gauss.sum()\n","\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average=True):\n","    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n","\n","    C1 = 0.01 ** 2\n","    C2 = 0.03 ** 2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","def ssim(img1, img2, window_size=11, size_average=True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","\n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","\n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.931733Z","iopub.status.busy":"2023-07-18T20:38:35.931181Z","iopub.status.idle":"2023-07-18T20:38:35.944824Z","shell.execute_reply":"2023-07-18T20:38:35.943719Z","shell.execute_reply.started":"2023-07-18T20:38:35.931694Z"},"trusted":true},"outputs":[],"source":["results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:38:35.947173Z","iopub.status.busy":"2023-07-18T20:38:35.946548Z","iopub.status.idle":"2023-07-18T20:53:39.952339Z","shell.execute_reply":"2023-07-18T20:53:39.949248Z","shell.execute_reply.started":"2023-07-18T20:38:35.947130Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[1/10] Loss_D: 0.7481 Loss_G: 0.0567 D(x): 0.6197 D(G(z)): 0.3298: 100%|██████████| 13/13 [01:07<00:00,  5.21s/it]\n","[converting LR images to SR images] PSNR: 12.5204 dB SSIM: 0.3783: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n","[2/10] Loss_D: 0.3491 Loss_G: 0.0293 D(x): 0.8164 D(G(z)): 0.1420: 100%|██████████| 13/13 [01:04<00:00,  4.93s/it]\n","[converting LR images to SR images] PSNR: 16.5666 dB SSIM: 0.4497: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n","[3/10] Loss_D: 0.1848 Loss_G: 0.0250 D(x): 0.9062 D(G(z)): 0.0728: 100%|██████████| 13/13 [01:02<00:00,  4.84s/it]\n","[converting LR images to SR images] PSNR: 17.4948 dB SSIM: 0.4380: 100%|██████████| 100/100 [00:26<00:00,  3.80it/s]\n","[4/10] Loss_D: 0.4310 Loss_G: 0.0208 D(x): 0.7347 D(G(z)): 0.1220: 100%|██████████| 13/13 [01:02<00:00,  4.82s/it]\n","[converting LR images to SR images] PSNR: 17.1715 dB SSIM: 0.4611: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n","[5/10] Loss_D: 0.2221 Loss_G: 0.0171 D(x): 0.8669 D(G(z)): 0.0695: 100%|██████████| 13/13 [01:03<00:00,  4.86s/it]\n","[converting LR images to SR images] PSNR: 18.7782 dB SSIM: 0.4957: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n","[6/10] Loss_D: 0.0572 Loss_G: 0.0154 D(x): 0.9671 D(G(z)): 0.0204: 100%|██████████| 13/13 [01:04<00:00,  4.99s/it]\n","[converting LR images to SR images] PSNR: 17.7535 dB SSIM: 0.5040: 100%|██████████| 100/100 [00:26<00:00,  3.74it/s]\n","[7/10] Loss_D: 0.0201 Loss_G: 0.0150 D(x): 0.9893 D(G(z)): 0.0078: 100%|██████████| 13/13 [01:02<00:00,  4.82s/it]\n","[converting LR images to SR images] PSNR: 18.3401 dB SSIM: 0.5138: 100%|██████████| 100/100 [00:26<00:00,  3.74it/s]\n","[8/10] Loss_D: 0.0102 Loss_G: 0.0136 D(x): 0.9943 D(G(z)): 0.0043: 100%|██████████| 13/13 [01:02<00:00,  4.79s/it]\n","[converting LR images to SR images] PSNR: 19.2828 dB SSIM: 0.5217: 100%|██████████| 100/100 [00:26<00:00,  3.73it/s]\n","[9/10] Loss_D: 0.0073 Loss_G: 0.0130 D(x): 0.9962 D(G(z)): 0.0033: 100%|██████████| 13/13 [01:01<00:00,  4.71s/it]\n","[converting LR images to SR images] PSNR: 19.0087 dB SSIM: 0.5231: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n","[10/10] Loss_D: 0.0066 Loss_G: 0.0131 D(x): 0.9968 D(G(z)): 0.0028: 100%|██████████| 13/13 [01:02<00:00,  4.78s/it]\n","[converting LR images to SR images] PSNR: 19.7881 dB SSIM: 0.5410: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"]}],"source":["for epoch in range(1, num_epochs + 1):\n","        train_bar = tqdm(train_loader)\n","        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n","    \n","        netG.train()\n","        netD.train()\n","        for data, target in train_bar:\n","            g_update_first = True\n","            batch_size = data.size(0)\n","            running_results['batch_sizes'] += batch_size\n","    \n","            ############################\n","            # (1) Update D network: maximize D(x)-1-D(G(z))\n","            ###########################\n","            real_img = Variable(target)\n","            if torch.cuda.is_available():\n","                real_img = real_img.cuda()\n","            z = Variable(data)\n","            if torch.cuda.is_available():\n","                z = z.cuda()\n","            fake_img = netG(z)\n","    \n","            netD.zero_grad()\n","            real_out = netD(real_img).mean()\n","            fake_out = netD(fake_img).mean()\n","            d_loss = 1 - real_out + fake_out\n","            d_loss.backward(retain_graph=True)\n","            optimizerD.step()\n","    \n","            ############################\n","            # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n","            ###########################\n","            netG.zero_grad()\n","            ## The two lines below are added to prevent runetime error in Google Colab ##\n","            fake_img = netG(z)\n","            fake_out = netD(fake_img).mean()\n","            ##\n","            g_loss = generator_criterion(fake_out, fake_img, real_img)\n","            g_loss.backward()\n","            \n","            fake_img = netG(z)\n","            fake_out = netD(fake_img).mean()\n","            \n","            \n","            optimizerG.step()\n","\n","            # loss for current batch before optimization \n","            running_results['g_loss'] += g_loss.item() * batch_size\n","            running_results['d_loss'] += d_loss.item() * batch_size\n","            running_results['d_score'] += real_out.item() * batch_size\n","            running_results['g_score'] += fake_out.item() * batch_size\n","    \n","            train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n","                epoch, num_epochs, running_results['d_loss'] / running_results['batch_sizes'],\n","                running_results['g_loss'] / running_results['batch_sizes'],\n","                running_results['d_score'] / running_results['batch_sizes'],\n","                running_results['g_score'] / running_results['batch_sizes']))\n","    \n","        netG.eval()\n","        \n","        with torch.no_grad():\n","            val_bar = tqdm(val_loader)\n","            valid_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n","            val_images = []\n","            for val_lr, val_hr_restore, val_hr in val_bar:\n","                batch_size = val_lr.size(0)\n","                valid_results['batch_sizes'] += batch_size\n","                lr = val_lr\n","                hr = val_hr\n","                if torch.cuda.is_available():\n","                    lr = lr.cuda()\n","                    hr = hr.cuda()\n","                sr = netG(lr)\n","        \n","                batch_mse = ((sr - hr) ** 2).data.mean()\n","                valid_results['mse'] += batch_mse * batch_size\n","                batch_ssim = ssim(sr, hr).item()\n","                valid_results['ssims'] += batch_ssim * batch_size\n","                valid_results['psnr'] = 10 * math.log10((hr.max()**2) / (valid_results['mse'] / valid_results['batch_sizes']))\n","                valid_results['ssim'] = valid_results['ssims'] / valid_results['batch_sizes']\n","                val_bar.set_description(\n","                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n","                        valid_results['psnr'], valid_results['ssim']))\n","        \n","        if not os.path.exists('epochs/'):\n","          os.makedirs('epochs/')\n","        # save model parameters\n","        if epoch%10==0:\n","          torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (upscale_factor, epoch))\n","          torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (upscale_factor, epoch))\n","        # save loss\\scores\\psnr\\ssim\n","        results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n","        results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n","        results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n","        results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n","        results['psnr'].append(valid_results['psnr'])\n","        results['ssim'].append(valid_results['ssim'])\n","    \n","        if epoch % 10 == 0 and epoch != 0:\n","            out_path = 'statistics/'\n","            if not os.path.exists(out_path):\n","              os.makedirs(out_path)\n","            \n","            data_frame = pd.DataFrame(\n","                data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n","                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n","                index=range(1, epoch + 1))\n","            data_frame.to_csv(out_path + 'srf_' + str(upscale_factor) + '_train_results.csv', index_label='Epoch')\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:55:30.497220Z","iopub.status.busy":"2023-07-18T20:55:30.495966Z","iopub.status.idle":"2023-07-18T20:55:30.561042Z","shell.execute_reply":"2023-07-18T20:55:30.559983Z","shell.execute_reply.started":"2023-07-18T20:55:30.497168Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["upscale_factor = 8\n","model_name = \"netG_epoch_8_20.pth\"\n","model = Generator(upscale_factor).eval()\n","device=torch.device('gpu')\n","model = model.to(device)\n","model.load_state_dict(torch.load('/kaggle/working/epochs/netG_epoch_8_10.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T20:55:31.850697Z","iopub.status.busy":"2023-07-18T20:55:31.850121Z"},"trusted":true},"outputs":[],"source":["# pass any other image, if needed\n","image_name= \"/kaggle/input/div2k-dataset/DIV2K_train_HR/DIV2K_train_HR/0002.png\"\n","image = Image.open(image_name)\n","image = Variable(transforms.ToTensor()(image)).unsqueeze(0).to(device)\n","out = model(image)\n","out_img = transforms.ToPILImage()(out[0].data.cpu())\n","out_img.save('output.jpeg')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(image.shape)\n","print(out_img.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.imshow(image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.imshow(out_img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
